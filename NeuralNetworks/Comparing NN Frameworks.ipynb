{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-17T04:30:53.692133Z",
     "start_time": "2025-06-17T04:30:29.583006Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(train_images, train_activityels), (test_images, test_activityels) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize the images to a range of 0 to 1\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001B[1m170498071/170498071\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 0us/step\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T04:34:19.787145Z",
     "start_time": "2025-06-17T04:34:19.758742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ],
   "id": "ba249dcb217fff5e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T04:34:20.809803Z",
     "start_time": "2025-06-17T04:34:20.795907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ],
   "id": "edda4a6285cf91ea",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T04:35:31.542910Z",
     "start_time": "2025-06-17T04:34:21.992282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the model for 10 epochs\n",
    "model.fit(train_images, train_activityels, epochs=10, batch_size=32, validation_data=(test_images, test_activityels))"
   ],
   "id": "494edb837abaad50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 4ms/step - accuracy: 0.4032 - loss: 1.6476 - val_accuracy: 0.5967 - val_loss: 1.1437\n",
      "Epoch 2/10\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 4ms/step - accuracy: 0.6138 - loss: 1.1146 - val_accuracy: 0.6518 - val_loss: 1.0200\n",
      "Epoch 3/10\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 4ms/step - accuracy: 0.6645 - loss: 0.9690 - val_accuracy: 0.6761 - val_loss: 0.9435\n",
      "Epoch 4/10\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 4ms/step - accuracy: 0.7008 - loss: 0.8643 - val_accuracy: 0.6827 - val_loss: 0.9260\n",
      "Epoch 5/10\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 5ms/step - accuracy: 0.7249 - loss: 0.7931 - val_accuracy: 0.6624 - val_loss: 0.9765\n",
      "Epoch 6/10\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 4ms/step - accuracy: 0.7480 - loss: 0.7206 - val_accuracy: 0.6992 - val_loss: 0.8981\n",
      "Epoch 7/10\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 4ms/step - accuracy: 0.7660 - loss: 0.6713 - val_accuracy: 0.7043 - val_loss: 0.8839\n",
      "Epoch 8/10\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 4ms/step - accuracy: 0.7878 - loss: 0.6087 - val_accuracy: 0.6986 - val_loss: 0.9149\n",
      "Epoch 9/10\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 4ms/step - accuracy: 0.8063 - loss: 0.5619 - val_accuracy: 0.7051 - val_loss: 0.9254\n",
      "Epoch 10/10\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 4ms/step - accuracy: 0.8215 - loss: 0.5123 - val_accuracy: 0.6931 - val_loss: 0.9711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2469f0f15a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T04:35:41.842192Z",
     "start_time": "2025-06-17T04:35:41.178536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_activityels)\n",
    "print(f'Test accuracy: {test_acc}')"
   ],
   "id": "8b2a59226b91f314",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.6948 - loss: 0.9553\n",
      "Test accuracy: 0.6930999755859375\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T04:36:35.689033Z",
     "start_time": "2025-06-17T04:36:34.458986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define a transformation to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)"
   ],
   "id": "d707542c8d39d326",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T04:36:36.602228Z",
     "start_time": "2025-06-17T04:36:36.588687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.fc1 = nn.Linear(64 * 6 * 6, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 64 * 6 * 6)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "id": "5b8abfb34459c100",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T04:36:38.217291Z",
     "start_time": "2025-06-17T04:36:38.203155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Make sure to define the model using the PyTorch-defined CNN\n",
    "model = SimpleCNN()  # Ensure this is the PyTorch model\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "id": "7a78b8168a12701f",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T04:40:17.470250Z",
     "start_time": "2025-06-17T04:36:47.297415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training loop for PyTorch\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for inputs, activityels in trainloader:\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, activityels)  # Calculate loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Optimize\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}')"
   ],
   "id": "fa74e9b1f197e26f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.4237866758995155\n",
      "Epoch 2, Loss: 1.0790046883254805\n",
      "Epoch 3, Loss: 0.9437588436894896\n",
      "Epoch 4, Loss: 0.8529703192655962\n",
      "Epoch 5, Loss: 0.7861231527340694\n",
      "Epoch 6, Loss: 0.7308071951452769\n",
      "Epoch 7, Loss: 0.684646140896046\n",
      "Epoch 8, Loss: 0.6431198913892415\n",
      "Epoch 9, Loss: 0.609124870938669\n",
      "Epoch 10, Loss: 0.5744062982361361\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T04:40:28.224506Z",
     "start_time": "2025-06-17T04:40:25.129664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, activityels in testloader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += activityels.size(0)\n",
    "        correct += (predicted == activityels).sum().item()\n",
    "\n",
    "print(f'Test accuracy: {100 * correct / total}%')"
   ],
   "id": "982868ae585f77b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 70.67%\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7aa42446b5d29891"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
